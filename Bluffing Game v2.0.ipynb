{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bluffing Game ML Project\n",
    "\n",
    "Version 2.0  \n",
    "\n",
    "Have players A and B both evolve\n",
    "\n",
    "Verson 1.1 -- Diagnose why starting at 1% the learning never finds that raising on a high card is correct.\n",
    "\n",
    "Version  1.0\n",
    "\n",
    "Convert strategies to vectors\n",
    "\n",
    "Build learning framework\n",
    "\n",
    "Logistic regression learning - one strat at at time vs. optimal\n",
    "\n",
    "Build convergence testing and find good hyperparameters\n",
    "\n",
    "Explore\n",
    "\n",
    "Version 0.0\n",
    "\n",
    "Get core code for gameplay and basic strategies to work.\n",
    "\n",
    "\n",
    "Objective\n",
    "\n",
    "This code plays the following Poker like bluffing game and evolves strategies using reinforcement learning.  I am doing this to practice Python code and to experiment with ML methods.\n",
    "\n",
    "The game works as follows.  Two players, A and B, each bets 1 dollars.  They are each given a random card from a deck D  (a set of numbers initially discrete, may change to continuous).  Player A can then decide to pass, in which case the higher card gets the 2 dollars, or raise, adding another dollar to the pot.  If A raises, B chooses either to fold, in which case A gets the pot, or call, in which case the holder of the highest card gets the 4 dollar pot.  If they are equal, they split.  Thus the payouts are as follows.\n",
    "\n",
    "| A Choice | B Choice | Higher Card | Payout to A | Payout to B|\n",
    "|----------|----------|-------------|-------------|------------|\n",
    "| Pass     | N/A      |  A          |      +1     |      -1    |\n",
    "| Pass     | N/A      |  B          |      -1     |      +1    |\n",
    "| Pass     | N/A      |  Tie        |       0     |       0    |\n",
    "| Raise    | Fold     |  N/A        |      +1     |      -1    |\n",
    "| Raise    | Call     |  A          |      +2     |      -2    |\n",
    "| Raise    | Call     |  B          |      -2     |      +2    |\n",
    "| Raise    | Call     |  Tie        |       0     |       0    |\n",
    "|----------|----------|-------------|-------------|------------|\n",
    "\n",
    "Idea is from https://fivethirtyeight.com/features/dont-throw-out-that-calendar/ where the game is analyzed for a die role, i.e. the set {1,2,3,4,5,6}.  There is an optimum mixed strategy for A involving bluffing, and multiple optimum strategies -- all mixed -- for B.  I want to see if, and how fast, ML can find these strategies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Playgame routine.  Plays one game between StratA and StratB.  Outputs return to A\n",
    "    Added output of cards and plays to allow ML\"\"\"\n",
    "\n",
    "def playgame(GameDeck, StratA, StratB, verbose = False):\n",
    "\n",
    "    # Deal \n",
    "    cardA = GameDeck.deal()\n",
    "    cardB = GameDeck.deal()\n",
    "    if verbose: print(\"Card A: \", cardA, \" Card B: \", cardB)\n",
    "    playA = \"\"\n",
    "    playB = \"\"\n",
    "    \n",
    "    # Player A decides\n",
    "    playA = StratA.play(cardA,\"A\")\n",
    "    if verbose: print(\"Player A: \", playA)\n",
    "\n",
    "    # if Player A pass, showdown for $2    \n",
    "    if playA == \"Pass\":\n",
    "        if cardA > cardB:\n",
    "            payout = 1\n",
    "        elif cardB > cardA:\n",
    "            payout = -1\n",
    "        else:\n",
    "            payout = 0\n",
    "    # if Player A raises, player B decides\n",
    "    else:\n",
    "        playB = StratB.play(cardB,\"B\")\n",
    "        if verbose: print(\"Player B: \", playB)\n",
    "        \n",
    "        #if player B calls, showdown for $4\n",
    "        if playB == \"Call\":\n",
    "            if cardA > cardB:\n",
    "                payout = 2\n",
    "            elif cardB > cardA:\n",
    "                payout = -2\n",
    "            else:\n",
    "                assert (cardA == cardB)\n",
    "                payout = 0\n",
    "        # if player B folds, A gets the ante\n",
    "        else:\n",
    "            payout = 1\n",
    "    if verbose: \n",
    "        print(\"Payout: \",payout)\n",
    "        print(\"\")\n",
    "    return {'winA':payout,'playA':playA,'playB':playB,'cardA':cardA,'cardB':cardB}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Deck class  Defines the deck.  For now only a discrete set 0 - n-1\"\"\"\n",
    "\n",
    "class Deck:\n",
    "    def __init__(self, decksize):\n",
    "        self.decksize = decksize\n",
    "        self.cards = range(self.decksize)      \n",
    "        \n",
    "    def deal(self):\n",
    "        import random              # is it ok to have this here?\n",
    "        card_delt = random.randint(0,self.decksize -1 )\n",
    "        return card_delt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"  Strategy Class.  Sets standards for all strategies \n",
    "    Create a subclass for each strategy\"\"\"\n",
    "\n",
    "class Strategy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # self.gamedeck = GameDeck\n",
    "        # self.decksize = GameDeck.decksize\n",
    "        \n",
    "    def play(self,mycard,player):\n",
    "        \"\"\" determine strategy for player, having been dealt card mycard.  \n",
    "        If player = \"A\" return either 'Pass' or 'Raise' \n",
    "        If player = 'B' return either 'Fold' or 'Call' \"\"\" \n",
    "        pass\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Vector based strategy.  \n",
    "\n",
    "    Paramaterized by a vector giving probability of aggressive (Raise/Call) strategy for each card.\n",
    "    \n",
    "    Old strategies\n",
    "    \n",
    "    Random - [1/2,1/2,1/2,1/2,1/2,1/2]\n",
    "    Simple - e.g [0,0,0,1,1,1] \n",
    "    bluff - e.g [p,p,p,1,1,1]\n",
    "    optimal - A [2/3,0,0,0,1,1]  B [0, 1/3,1/3,1,1,1]\"\"\"\n",
    "\n",
    "class vectorstrat(Strategy):\n",
    "    \n",
    "    def __init__(self,aggprobs):\n",
    "        self.aggprobs = aggprobs\n",
    "        \n",
    "    def play(self,mycard,player):\n",
    "        import random\n",
    "        if random.random() > self.aggprobs[mycard]:\n",
    "            if player == \"A\":\n",
    "                return 'Pass'\n",
    "            else:\n",
    "                return 'Fold'\n",
    "        else:\n",
    "            if player == \"A\":\n",
    "                return \"Raise\"\n",
    "            else:\n",
    "                return 'Call'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Challenge Routine.\n",
    "Plays n games between two strategies and returns the net result.\n",
    "Used for testing\n",
    "\"\"\"\n",
    "\n",
    "def challenge(num_games,strata,stratb,strataname = \"\",stratbname = \"\",verbose = False):\n",
    "\n",
    "    decksize = 6\n",
    "    d = Deck(decksize)\n",
    "\n",
    "    a_net_wins = 0\n",
    "\n",
    "    if verbose: print(\"Player A: \", strataname,\"   Player B: \", stratbname )\n",
    "\n",
    "    for i in range (num_games):\n",
    "        a_net_wins += playgame(d,strata,stratb)['winA']\n",
    "        if verbose and i % 1000 == 0: print(i,\" games played\")\n",
    "\n",
    "    if verbose: print(strataname, \" won $\", a_net_wins, \"  $\", a_net_wins / num_games, \" per game.\")\n",
    "    \n",
    "    return a_net_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" A/B Learning  both learn together\n",
    "\n",
    "    Will use logistic regression to set each of the vector parameters individually.\n",
    "    \n",
    "    Inline training -- play one game, instantly update.\n",
    "    \n",
    "   \n",
    "    \n",
    "    \"\"\"\n",
    "import math\n",
    "def logit(x):\n",
    "    p = 1 / ( 1 + math.exp(-x))\n",
    "    return p\n",
    "\n",
    "def logodds(p):\n",
    "    if p == 0: return -10\n",
    "    elif p == 1: return 10\n",
    "    else:\n",
    "        x = math.log(p / (1-p))\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_AB_logit(num_games = 10 ** 6,num_updates = 20 , alpha = 0.005, decksize = 6,\n",
    "                  start_A =[], start_B =[],verbose = False,learnvsaverage = False,pass_win_reward=-1):\n",
    "\n",
    "    import random\n",
    "    import copy\n",
    "    \n",
    "    # set paramaters and counters\n",
    "\n",
    "    d = Deck(decksize)\n",
    "    \n",
    "    if start_A == [] :\n",
    "        paramvectorA = [0 for i in range(decksize)]  # starts random parameter = 0 -> prob 50%\n",
    "    else:\n",
    "        paramvectorA = [logodds(p) for p in start_A]\n",
    "        \n",
    "    \n",
    "\n",
    "    if start_B == []:   # default for B is also 50%\n",
    "        paramvectorB = [0 for i in range(decksize)]\n",
    "    else:\n",
    "        paramvectorB = [logodds(p) for p in start_B]\n",
    "        \n",
    "    \n",
    "    winningsA = 0\n",
    "    winningsA_temp = 0\n",
    "    training_updates =[]\n",
    "    games_update = num_games / num_updates\n",
    "    \n",
    "    \n",
    "    for i in range(num_games+1):\n",
    "        \n",
    "        # set strategy to current logit of parameters for both A and B\n",
    "        strategyvectorA = [logit(x) for x in paramvectorA]\n",
    "        sa = vectorstrat(strategyvectorA)\n",
    "        \n",
    "        strategyvectorB = [logit(x) for x in paramvectorB]\n",
    "        sb = vectorstrat(strategyvectorB)\n",
    "\n",
    "        #play a game\n",
    "        result = playgame(d,sa,sb,verbose = False)\n",
    "        \n",
    "        # direction of update is positive for a plus action.  Maybe change action from string to +/- 1\n",
    "        if result['playA'] == \"Raise\":\n",
    "            directionA = 1\n",
    "        else:\n",
    "            if result['winA'] > 0 :\n",
    "                directionA =  - pass_win_reward\n",
    "            else:\n",
    "                directionA = -1\n",
    "                \n",
    "        if result['playB'] == \"Call\":\n",
    "            directionB = 1\n",
    "        else:\n",
    "            directionB = -1\n",
    "        \n",
    "        # update strategy.  Alpha is change rate parameter.  \n",
    "        # Result * direction positive when aggression paid off or passive resulted in loss -> increase prob.\n",
    "        # idea -- change result to result - average\n",
    "        avgwins = 0\n",
    "        if learnvsaverage:\n",
    "            avgwins = winnings / i\n",
    "            \n",
    "        paramvectorA[result['cardA']] += alpha * (result['winA']-avgwins) *  directionA\n",
    "        \n",
    "        if result['playA'] == \"Raise\":   # B only has a decision when A raises\n",
    "            paramvectorB[result['cardB']] += alpha * (-1) * (result['winA'] - avgwins) * directionB\n",
    "            #if result['cardB'] == 0:\n",
    "            #    print('cardA: ', result['cardA'],\" cardB: \",result['cardB'], \" playB: \",\n",
    "            #          result['playB'],\" A Wins: \",result['winA'],\n",
    "            #          ' learning:',alpha * (-1) * (result['winA'] - avgwins) * directionB)\n",
    "        \n",
    "      \n",
    "        # avoid over/underflow errors  Likely a better method, but this works within 1%\n",
    "        paramvectorA[result['cardA']] = max(-10,paramvectorA[result['cardA']])\n",
    "        paramvectorA[result['cardA']] = min(10,paramvectorA[result['cardA']])\n",
    "        paramvectorB[result['cardB']] = max(-10,paramvectorB[result['cardB']])\n",
    "        paramvectorB[result['cardB']] = min(10,paramvectorB[result['cardB']])\n",
    "        \n",
    "        \n",
    "        # track performance\n",
    "        winningsA += result['winA']\n",
    "        winningsA_temp += result['winA']\n",
    " \n",
    "        # periodically update\n",
    "        if i % games_update == 0 :\n",
    "            if verbose:\n",
    "                if i > 0: \n",
    "                    tempwinrate = round(winningsA_temp / games_update,4) \n",
    "                else: \n",
    "                    tempwinrate = \"       \"\n",
    "                print(i, tempwinrate,'A:',[round(logit(x)*100,2) for x in paramvectorA],\n",
    "                      \" B: \",[round(logit(x)*100,2) for x in paramvectorB])    \n",
    "            training_updates += [{'games':i,'tempAwins':winningsA_temp,\n",
    "                                  'logoddsA':copy.deepcopy(paramvectorA),'logoddsB':copy.deepcopy(paramvectorB)}]\n",
    "            winningsA_temp = 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "        winrateA = winningsA / num_games\n",
    "        print(\"A's Winrate = \", winrateA)\n",
    "        print([round(x,4) for x in paramvectorA])\n",
    "        strategyvector = [round(logit(x)*100,2)  for x in paramvectorA]\n",
    "        print(strategyvectorA)\n",
    "        print([round(x,4) for x in paramvectorB])\n",
    "        strategyvector = [round(logit(x)*100,2)  for x in paramvectorB]\n",
    "        print(strategyvectorA)\n",
    "        \n",
    "    return {'num_games':num_games, 'winningsA':winningsA,'final model A':paramvectorA,\n",
    "            'final model B':paramvectorB,'training_updates':training_updates}\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A: [50.0, 50.0, 50.0, 50.0, 50.25, 50.0]  B:  [49.75, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
      "50000 0.0636 A: [55.48, 50.12, 67.92, 99.48, 100.0, 100.0]  B:  [36.94, 40.37, 54.98, 88.65, 100.0, 100.0]\n",
      "100000 0.0572 A: [52.0, 52.62, 67.7, 99.98, 100.0, 100.0]  B:  [37.75, 45.88, 53.99, 88.13, 100.0, 100.0]\n",
      "150000 0.0541 A: [49.0, 59.27, 68.89, 99.99, 100.0, 100.0]  B:  [36.47, 47.13, 55.48, 85.32, 100.0, 100.0]\n",
      "200000 0.0435 A: [49.0, 53.49, 67.15, 100.0, 100.0, 100.0]  B:  [37.17, 40.61, 53.37, 85.57, 100.0, 100.0]\n",
      "250000 0.0652 A: [45.26, 60.47, 69.95, 99.99, 100.0, 100.0]  B:  [36.47, 42.43, 52.5, 84.55, 100.0, 100.0]\n",
      "300000 0.0434 A: [41.1, 55.11, 64.91, 99.99, 100.0, 100.0]  B:  [36.59, 39.53, 52.25, 85.38, 100.0, 100.0]\n",
      "350000 0.049 A: [51.0, 55.72, 71.5, 100.0, 100.0, 100.0]  B:  [32.52, 42.19, 53.62, 83.69, 100.0, 100.0]\n",
      "400000 0.0625 A: [47.25, 53.0, 65.7, 100.0, 100.0, 100.0]  B:  [30.26, 43.66, 54.61, 87.32, 100.0, 100.0]\n",
      "450000 0.0416 A: [46.26, 52.75, 63.3, 100.0, 100.0, 100.0]  B:  [35.55, 43.91, 56.09, 86.24, 100.0, 100.0]\n",
      "500000 0.0571 A: [47.0, 53.62, 70.68, 99.99, 100.0, 100.0]  B:  [34.07, 41.1, 55.85, 86.0, 100.0, 100.0]\n",
      "550000 0.0538 A: [46.88, 51.0, 71.81, 100.0, 100.0, 100.0]  B:  [33.51, 40.85, 53.25, 86.82, 100.0, 100.0]\n",
      "600000 0.0492 A: [47.25, 57.32, 67.59, 100.0, 100.0, 100.0]  B:  [33.29, 44.65, 53.25, 83.75, 100.0, 100.0]\n",
      "650000 0.0538 A: [49.25, 53.37, 69.74, 100.0, 100.0, 100.0]  B:  [32.19, 41.46, 54.12, 85.57, 100.0, 100.0]\n",
      "700000 0.046 A: [48.13, 52.25, 64.79, 100.0, 100.0, 100.0]  B:  [32.63, 43.05, 48.75, 89.98, 100.0, 100.0]\n",
      "750000 0.0407 A: [45.14, 53.0, 69.1, 99.99, 100.0, 100.0]  B:  [38.82, 38.23, 52.37, 85.38, 100.0, 100.0]\n",
      "800000 0.0514 A: [46.51, 56.46, 69.95, 99.99, 100.0, 100.0]  B:  [34.86, 41.22, 55.23, 82.27, 100.0, 100.0]\n",
      "850000 0.0452 A: [46.88, 52.37, 72.61, 100.0, 100.0, 100.0]  B:  [32.3, 40.37, 56.71, 83.27, 100.0, 100.0]\n",
      "900000 0.0464 A: [44.77, 53.87, 66.93, 99.99, 100.0, 100.0]  B:  [34.19, 41.1, 51.62, 86.12, 100.0, 100.0]\n",
      "950000 0.0488 A: [44.15, 53.37, 71.71, 100.0, 100.0, 100.0]  B:  [38.46, 41.22, 56.09, 89.93, 100.0, 100.0]\n",
      "1000000 0.0517 A: [43.91, 50.0, 66.6, 99.99, 100.0, 100.0]  B:  [35.89, 43.41, 51.75, 89.61, 100.0, 100.0]\n",
      "Done\n",
      "A's Winrate =  0.051207\n",
      "[-0.245, 0.0, 0.69, 9.89, 10, 10]\n",
      "[0.4390545496753121, 0.5000000000000245, 0.6648537304058952, 0.9999493236222312, 0.9999546021312976, 0.9999546021312976]\n",
      "[-0.58, -0.265, 0.07, 2.155, 10, 10]\n",
      "[0.4390545496753121, 0.5000000000000245, 0.6648537304058952, 0.9999493236222312, 0.9999546021312976, 0.9999546021312976]\n"
     ]
    }
   ],
   "source": [
    "t = train_AB_logit(num_games = 10**6,num_updates = 20 , alpha = 0.005, decksize = 6,\n",
    "                  start_A =[], start_B =[],verbose = True,learnvsaverage = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First try \n",
    "A bit closer to the analytic solution.\n",
    "Both learn to raise/call with high card very quickly.\n",
    "However, something is odd with B on low card. This should quickly converge to zero, as there should be no positive inforcement.  But the param is sometimes going back up.  Adding some diagnostic printing to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A: [50.0, 50.0, 50.12, 50.0, 50.0, 50.0]  B:  [50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
      "5 1.0 A: [50.0, 50.12, 50.12, 50.0, 50.0, 50.5]  B:  [50.0, 49.75, 50.0, 50.12, 50.12, 50.0]\n",
      "10 -0.2 A: [50.12, 50.12, 50.0, 50.0, 50.0, 50.62]  B:  [50.0, 49.75, 50.0, 50.12, 50.5, 50.0]\n",
      "cardA:  2  cardB:  0  playB:  Call  A Wins:  2  learning: -0.01\n",
      "15 0.6 A: [50.12, 50.12, 50.0, 50.0, 50.0, 51.0]  B:  [49.75, 49.75, 50.0, 50.12, 50.25, 50.25]\n",
      "cardA:  0  cardB:  0  playB:  Fold  A Wins:  1  learning: 0.005\n",
      "cardA:  4  cardB:  0  playB:  Call  A Wins:  2  learning: -0.01\n",
      "20 0.0 A: [50.25, 50.12, 50.0, 49.75, 50.37, 51.0]  B:  [49.63, 49.75, 50.0, 50.12, 50.25, 50.5]\n",
      "cardA:  1  cardB:  0  playB:  Call  A Wins:  2  learning: -0.01\n",
      "25 0.8 A: [50.25, 50.62, 50.0, 49.88, 50.37, 51.12]  B:  [49.38, 49.88, 50.0, 50.12, 50.37, 50.5]\n",
      "30 0.6 A: [50.25, 50.62, 50.12, 50.12, 50.62, 51.37]  B:  [49.38, 49.63, 49.75, 50.12, 50.37, 50.5]\n",
      "35 1.0 A: [50.25, 50.62, 50.25, 50.25, 50.75, 51.62]  B:  [49.38, 49.63, 49.88, 50.12, 50.25, 50.5]\n",
      "40 -0.2 A: [50.0, 50.62, 50.25, 50.37, 50.75, 51.62]  B:  [49.38, 49.63, 50.12, 50.12, 50.25, 50.62]\n",
      "cardA:  1  cardB:  0  playB:  Fold  A Wins:  1  learning: 0.005\n",
      "45 -0.2 A: [49.75, 50.87, 50.37, 50.37, 51.0, 51.62]  B:  [49.5, 49.63, 50.12, 49.88, 50.5, 50.62]\n",
      "cardA:  3  cardB:  0  playB:  Fold  A Wins:  1  learning: 0.005\n",
      "50 1.0 A: [49.75, 50.87, 50.5, 50.5, 51.0, 52.0]  B:  [49.63, 49.63, 49.88, 49.88, 50.5, 50.75]\n",
      "cardA:  2  cardB:  0  playB:  Call  A Wins:  2  learning: -0.01\n",
      "55 0.2 A: [49.75, 50.87, 50.87, 50.62, 51.12, 52.0]  B:  [49.38, 49.63, 50.0, 49.88, 50.5, 50.75]\n",
      "60 0.6 A: [49.88, 51.0, 50.87, 50.62, 51.37, 52.12]  B:  [49.38, 49.63, 49.75, 49.88, 50.5, 50.75]\n",
      "65 0.2 A: [50.12, 51.12, 50.87, 50.62, 51.37, 52.37]  B:  [49.38, 49.75, 49.5, 49.88, 50.5, 50.75]\n",
      "cardA:  3  cardB:  0  playB:  Fold  A Wins:  1  learning: 0.005\n",
      "70 0.6 A: [50.12, 51.25, 51.0, 51.0, 51.37, 52.37]  B:  [49.5, 49.75, 49.25, 49.88, 50.5, 50.75]\n",
      "75 -0.6 A: [49.88, 51.25, 51.12, 50.75, 51.37, 52.62]  B:  [49.5, 49.75, 49.5, 49.88, 50.5, 50.75]\n",
      "cardA:  0  cardB:  0  playB:  Fold  A Wins:  1  learning: 0.005\n",
      "80 1.2 A: [50.0, 51.25, 51.12, 50.75, 51.75, 52.87]  B:  [49.63, 49.63, 49.63, 49.88, 50.5, 50.87]\n",
      "85 0.0 A: [50.12, 51.37, 51.12, 50.87, 51.87, 52.87]  B:  [49.63, 49.63, 49.63, 49.88, 50.62, 51.0]\n",
      "90 0.8 A: [50.12, 51.37, 51.12, 50.87, 51.87, 53.37]  B:  [49.63, 49.63, 49.38, 49.88, 50.62, 51.0]\n",
      "95 -0.4 A: [50.0, 51.5, 51.12, 51.0, 52.0, 53.37]  B:  [49.63, 49.75, 49.75, 49.88, 50.62, 51.0]\n",
      "100 1.0 A: [50.0, 51.5, 51.12, 51.25, 52.12, 53.62]  B:  [49.63, 49.75, 49.75, 49.88, 50.75, 51.0]\n",
      "Done\n",
      "A's Winrate =  0.39\n",
      "[0.0, 0.06, 0.045, 0.05, 0.085, 0.145]\n",
      "[0.5, 0.51499550161941, 0.5112481019468548, 0.5124973964842103, 0.5212372149662741, 0.5349429451582145]\n",
      "[-0.015, -0.01, -0.01, -0.005, 0.03, 0.04]\n",
      "[0.5, 0.51499550161941, 0.5112481019468548, 0.5124973964842103, 0.5212372149662741, 0.5349429451582145]\n"
     ]
    }
   ],
   "source": [
    "t = train_AB_logit(num_games = 100,num_updates = 20 , alpha = 0.005, decksize = 6,\n",
    "                  start_A =[], start_B =[],verbose = True,learnvsaverage = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue now clear.  Similar issue to before.\n",
    "\n",
    "When B folds, he loses, so gets discouraged from folding, even though this was the right move.\n",
    "This is a limitation of the linear approach.\n",
    "It could be that with enough games the greater feedback of the $2 loss on a raise will eventually get the right solution.  Try another run with higher alpha and more games to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A: [50.0, 50.0, 51.25, 50.0, 50.0, 50.0]  B:  [50.0, 48.75, 50.0, 50.0, 50.0, 50.0]\n",
      "500000 0.0478 A: [45.64, 46.26, 70.06, 99.99, 100.0, 100.0]  B:  [37.75, 43.78, 46.88, 90.25, 100.0, 100.0]\n",
      "1000000 0.0515 A: [50.0, 51.87, 59.27, 99.99, 100.0, 100.0]  B:  [41.34, 38.94, 54.98, 81.76, 100.0, 100.0]\n",
      "1500000 0.0494 A: [36.59, 60.47, 55.6, 99.99, 100.0, 100.0]  B:  [31.54, 47.5, 48.75, 93.55, 100.0, 100.0]\n",
      "2000000 0.0485 A: [45.02, 51.25, 71.61, 99.99, 100.0, 100.0]  B:  [31.0, 43.78, 56.83, 81.0, 100.0, 100.0]\n",
      "2500000 0.0431 A: [53.12, 51.87, 65.7, 99.99, 100.0, 100.0]  B:  [38.94, 40.13, 56.22, 86.12, 99.99, 100.0]\n",
      "3000000 0.0506 A: [44.4, 59.87, 72.11, 99.99, 100.0, 100.0]  B:  [38.34, 40.13, 52.5, 88.08, 100.0, 100.0]\n",
      "3500000 0.0522 A: [50.0, 60.47, 64.57, 100.0, 100.0, 100.0]  B:  [40.73, 46.26, 54.98, 89.57, 100.0, 100.0]\n",
      "4000000 0.0498 A: [53.12, 57.44, 83.2, 99.99, 100.0, 100.0]  B:  [37.75, 57.44, 51.87, 68.46, 100.0, 100.0]\n",
      "4500000 0.049 A: [44.4, 57.44, 67.92, 99.99, 100.0, 100.0]  B:  [29.94, 31.54, 59.27, 91.09, 100.0, 100.0]\n",
      "5000000 0.0484 A: [48.13, 59.87, 78.58, 100.0, 100.0, 100.0]  B:  [32.08, 46.88, 53.74, 85.51, 100.0, 100.0]\n",
      "5500000 0.0486 A: [50.62, 57.44, 81.76, 99.99, 100.0, 100.0]  B:  [36.59, 53.74, 44.4, 88.08, 100.0, 100.0]\n",
      "6000000 0.0491 A: [40.73, 54.98, 73.11, 99.99, 100.0, 100.0]  B:  [42.56, 40.13, 53.74, 91.29, 100.0, 100.0]\n",
      "6500000 0.045 A: [47.5, 58.05, 70.58, 99.99, 99.99, 100.0]  B:  [31.0, 36.59, 48.75, 85.51, 99.99, 100.0]\n",
      "7000000 0.0528 A: [42.56, 55.6, 67.92, 99.99, 100.0, 100.0]  B:  [34.3, 46.88, 51.87, 77.29, 100.0, 100.0]\n",
      "7500000 0.0495 A: [54.98, 45.64, 71.61, 100.0, 100.0, 100.0]  B:  [36.59, 45.64, 46.88, 89.57, 99.99, 100.0]\n",
      "8000000 0.0499 A: [56.22, 45.64, 72.61, 99.99, 100.0, 100.0]  B:  [36.59, 43.17, 54.98, 93.55, 100.0, 100.0]\n",
      "8500000 0.0501 A: [50.0, 53.12, 64.57, 99.99, 100.0, 100.0]  B:  [40.73, 52.5, 54.98, 88.84, 100.0, 100.0]\n",
      "9000000 0.0499 A: [39.53, 56.22, 70.58, 100.0, 100.0, 100.0]  B:  [33.18, 38.34, 45.02, 93.7, 99.99, 100.0]\n",
      "9500000 0.0479 A: [51.25, 71.09, 75.49, 99.99, 100.0, 100.0]  B:  [37.17, 36.01, 57.44, 90.47, 100.0, 100.0]\n",
      "10000000 0.0498 A: [43.17, 58.66, 59.87, 99.99, 100.0, 100.0]  B:  [35.43, 40.13, 50.62, 92.76, 100.0, 100.0]\n",
      "Done\n",
      "A's Winrate =  0.0491444\n",
      "[-0.275, 0.35, 0.4, 9.75, 10, 10]\n",
      "[0.43168001652309734, 0.5866175789188676, 0.5986876601090709, 0.9999417087343389, 0.9999546021312976, 0.9999546021312976]\n",
      "[-0.6, -0.4, 0.025, 2.55, 9.95, 10]\n",
      "[0.43168001652309734, 0.5866175789188676, 0.5986876601090709, 0.9999417087343389, 0.9999546021312976, 0.9999546021312976]\n"
     ]
    }
   ],
   "source": [
    "t = train_AB_logit(num_games = 10**7,num_updates = 20 , alpha = 0.025, decksize = 6,\n",
    "                  start_A =[], start_B =[],verbose = True,learnvsaverage = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B's strategy on low card still not converging towards zero. try again with very long slow learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A: [50.02, 50.0, 50.0, 50.0, 50.0, 50.0]  B:  [50.0, 50.02, 50.0, 50.0, 50.0, 50.0]\n",
      "5000000 0.0513 A: [45.19, 52.32, 69.06, 100.0, 100.0, 100.0]  B:  [35.94, 41.53, 53.62, 87.89, 100.0, 100.0]\n",
      "10000000 0.0499 A: [45.14, 51.77, 68.76, 100.0, 100.0, 100.0]  B:  [35.43, 41.31, 53.44, 88.48, 100.0, 100.0]\n",
      "15000000 0.0489 A: [46.16, 55.06, 67.55, 100.0, 100.0, 100.0]  B:  [35.64, 41.78, 53.02, 87.38, 100.0, 100.0]\n",
      "20000000 0.0499 A: [44.82, 51.35, 67.24, 100.0, 100.0, 100.0]  B:  [34.23, 42.6, 53.89, 89.24, 100.0, 100.0]\n",
      "25000000 0.0487 A: [45.12, 53.42, 66.73, 100.0, 100.0, 100.0]  B:  [36.47, 40.71, 55.63, 88.37, 100.0, 100.0]\n",
      "30000000 0.0499 A: [45.49, 55.9, 65.7, 100.0, 100.0, 100.0]  B:  [35.16, 42.75, 52.97, 87.79, 100.0, 100.0]\n",
      "35000000 0.0495 A: [45.44, 52.95, 67.22, 100.0, 100.0, 100.0]  B:  [34.62, 42.36, 53.99, 89.58, 100.0, 100.0]\n",
      "40000000 0.0488 A: [45.91, 55.87, 68.68, 100.0, 100.0, 100.0]  B:  [35.85, 44.28, 55.8, 87.61, 100.0, 100.0]\n",
      "45000000 0.0499 A: [45.88, 51.0, 67.63, 100.0, 100.0, 100.0]  B:  [34.86, 42.04, 56.34, 86.01, 100.0, 100.0]\n",
      "50000000 0.0493 A: [48.25, 53.74, 68.11, 100.0, 100.0, 100.0]  B:  [35.92, 41.39, 55.9, 87.31, 100.0, 100.0]\n",
      "55000000 0.0499 A: [46.11, 53.62, 69.44, 100.0, 100.0, 100.0]  B:  [35.18, 41.53, 53.67, 87.65, 100.0, 100.0]\n",
      "60000000 0.0485 A: [45.09, 55.43, 65.5, 100.0, 100.0, 100.0]  B:  [34.64, 41.41, 53.94, 88.72, 100.0, 100.0]\n",
      "65000000 0.0497 A: [45.07, 53.67, 67.48, 100.0, 100.0, 100.0]  B:  [35.94, 41.85, 53.1, 87.12, 100.0, 100.0]\n",
      "70000000 0.0498 A: [46.26, 51.6, 67.57, 100.0, 100.0, 100.0]  B:  [35.23, 41.75, 53.74, 88.48, 100.0, 100.0]\n",
      "75000000 0.0497 A: [45.66, 53.72, 67.74, 100.0, 100.0, 100.0]  B:  [37.82, 42.04, 55.28, 88.39, 100.0, 100.0]\n",
      "80000000 0.0494 A: [44.52, 53.25, 69.74, 100.0, 100.0, 100.0]  B:  [35.76, 42.63, 54.59, 88.35, 100.0, 100.0]\n",
      "85000000 0.0499 A: [45.79, 55.45, 69.4, 100.0, 100.0, 100.0]  B:  [36.61, 44.99, 51.37, 86.03, 100.0, 100.0]\n",
      "90000000 0.0487 A: [45.09, 53.0, 67.72, 100.0, 100.0, 100.0]  B:  [37.9, 41.8, 52.6, 86.97, 100.0, 100.0]\n",
      "95000000 0.0507 A: [49.23, 54.49, 67.08, 100.0, 100.0, 100.0]  B:  [36.8, 42.07, 52.62, 86.07, 100.0, 100.0]\n",
      "100000000 0.0505 A: [43.17, 54.54, 70.83, 100.0, 100.0, 100.0]  B:  [35.64, 41.07, 54.17, 86.46, 100.0, 100.0]\n",
      "105000000 0.0497 A: [46.23, 52.45, 69.17, 100.0, 100.0, 100.0]  B:  [35.92, 41.07, 53.47, 88.52, 100.0, 100.0]\n",
      "110000000 0.05 A: [44.62, 50.15, 67.13, 100.0, 100.0, 100.0]  B:  [35.39, 41.95, 53.47, 87.56, 100.0, 100.0]\n",
      "115000000 0.0503 A: [47.85, 54.54, 67.17, 100.0, 100.0, 100.0]  B:  [34.41, 41.41, 54.61, 85.83, 100.0, 100.0]\n",
      "120000000 0.0488 A: [45.54, 54.81, 65.52, 100.0, 100.0, 100.0]  B:  [35.0, 41.39, 54.59, 88.42, 100.0, 100.0]\n",
      "125000000 0.0496 A: [45.54, 54.09, 66.62, 100.0, 100.0, 100.0]  B:  [34.66, 39.96, 51.62, 88.78, 100.0, 100.0]\n",
      "130000000 0.0495 A: [45.54, 53.92, 68.35, 100.0, 100.0, 100.0]  B:  [37.12, 42.95, 55.06, 87.69, 100.0, 100.0]\n",
      "135000000 0.0497 A: [45.59, 54.86, 66.28, 100.0, 100.0, 100.0]  B:  [35.32, 41.14, 53.02, 89.05, 100.0, 100.0]\n",
      "140000000 0.0495 A: [47.85, 54.61, 69.0, 100.0, 100.0, 100.0]  B:  [37.05, 42.19, 54.19, 85.11, 100.0, 100.0]\n",
      "145000000 0.0481 A: [46.73, 54.91, 69.72, 100.0, 100.0, 100.0]  B:  [34.32, 43.19, 53.59, 87.88, 100.0, 100.0]\n",
      "150000000 0.0493 A: [47.08, 52.77, 67.46, 100.0, 100.0, 100.0]  B:  [34.77, 43.51, 54.61, 87.9, 100.0, 100.0]\n",
      "155000000 0.0498 A: [44.99, 53.82, 63.74, 100.0, 100.0, 100.0]  B:  [34.84, 41.78, 55.7, 89.45, 100.0, 100.0]\n",
      "160000000 0.0497 A: [46.18, 55.45, 66.04, 100.0, 100.0, 100.0]  B:  [35.39, 43.19, 53.49, 88.06, 100.0, 100.0]\n",
      "165000000 0.0508 A: [44.62, 53.62, 67.44, 100.0, 100.0, 100.0]  B:  [34.46, 43.81, 52.85, 88.35, 100.0, 100.0]\n",
      "170000000 0.0493 A: [45.61, 55.08, 67.59, 100.0, 100.0, 100.0]  B:  [34.64, 44.97, 54.83, 86.31, 100.0, 100.0]\n",
      "175000000 0.0491 A: [45.76, 54.02, 65.52, 100.0, 100.0, 100.0]  B:  [36.24, 41.46, 52.37, 87.74, 100.0, 100.0]\n",
      "180000000 0.049 A: [47.28, 53.64, 70.12, 100.0, 100.0, 100.0]  B:  [37.1, 39.84, 51.5, 86.26, 100.0, 100.0]\n",
      "185000000 0.05 A: [44.3, 53.49, 66.89, 100.0, 100.0, 100.0]  B:  [35.43, 42.31, 52.77, 89.04, 100.0, 100.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b7e4d00037bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m t = train_AB_logit(num_games = 10**9,num_updates = 200 , alpha = 0.001, decksize = 6,\n\u001b[0;32m----> 2\u001b[0;31m                   start_A =[], start_B =[],verbose = True,learnvsaverage = False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-ca47678a1414>\u001b[0m in \u001b[0;36mtrain_AB_logit\u001b[0;34m(num_games, num_updates, alpha, decksize, start_A, start_B, verbose, learnvsaverage, pass_win_reward)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#play a game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaygame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# direction of update is positive for a plus action.  Maybe change action from string to +/- 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6708fadab558>\u001b[0m in \u001b[0;36mplaygame\u001b[0;34m(GameDeck, StratA, StratB, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Deal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcardA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGameDeck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcardB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGameDeck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Card A: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Card B: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcardB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-32cad18cd5e4>\u001b[0m in \u001b[0;36mdeal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m              \u001b[0;31m# is it ok to have this here?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcard_delt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecksize\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcard_delt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"non-integer stop for randrange()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mistart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = train_AB_logit(num_games = 10**9,num_updates = 200 , alpha = 0.001, decksize = 6,\n",
    "                  start_A =[], start_B =[],verbose = True,learnvsaverage = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not converging.  Next round will need a better learning algo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
